{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/PhonePe/pulse.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the required libraries to extract the data,Manipulation of data and cleaning and to store it in our sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "mydb = mysql.connector.connect(host=\"localhost\",user=\"root\",password=\"\")\n",
    "mycursor = mydb.cursor(buffered=True)\n",
    "mycursor.execute('use capstone_2')\n",
    "username = 'root'\n",
    "password = ''\n",
    "host = 'localhost'  \n",
    "database_name = 'capstone_2'\n",
    "engine = create_engine(f'mysql+mysqlconnector://{username}:{password}@{host}/{database_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of the aggregated transaction data and data manipulation of that data using pandas data frame and storing that data in an sql database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1={'State':[],'Year':[],'Quater':[],'Transaction':[],'Count':[],'Amount':[]}\n",
    "path=r'C:\\Users\\kesav\\Guvi\\guvi main\\capstone_2\\pulse\\data\\aggregated\\transaction\\country\\india\\state'\n",
    "t=os.listdir(path)\n",
    "for i in t:\n",
    "    p1=path+'/'+i+'/'\n",
    "    t1=os.listdir(p1)\n",
    "    for j in t1:\n",
    "        p2=p1+'/'+j+'/'\n",
    "        t2=os.listdir(p2)\n",
    "        year = datetime.strptime(j, '%Y').year\n",
    "        for k in t2:\n",
    "            p3=p2+k\n",
    "            d=open(p3)\n",
    "            D=json.load(d)\n",
    "            for t in D['data']['transactionData']:\n",
    "                name=t['name']\n",
    "                c=t['paymentInstruments'][0]['count']\n",
    "                am=t['paymentInstruments'][0]['amount']\n",
    "                Data1['State'].append(i)\n",
    "                Data1['Year'].append(int(year))\n",
    "                Data1['Quater'].append(int(k.strip('.json')))\n",
    "                Data1['Transaction'].append(name)\n",
    "                Data1['Count'].append(c)\n",
    "                Data1['Amount'].append(am)\n",
    "Df1=pd.DataFrame(Data1)\n",
    "Df1['State'] = Df1['State'].str.replace('-&-', ' & ')\n",
    "Df1['State'] = Df1['State'].str.replace('-Islands', '')\n",
    "Df1['State'] = Df1['State'].str.replace('-', ' ')\n",
    "def cap(s):\n",
    "    return s.title()\n",
    "Df1['State']=Df1['State'].apply(cap)\n",
    "Df1['State'] = Df1['State'].str.replace('Islands', '')\n",
    "#mycursor.execute('use capstone_2')\n",
    "for i,row in Df1.iterrows():\n",
    "    #here %S means string values \n",
    "    sql = \"INSERT INTO t_1 VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "    mycursor.execute(sql, tuple(row))\n",
    "    # the connection is not auto committed by default, so we must commit to save our changes\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting of data and creating the data and storing the data in the sql for the aggregated users information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_r={'State':[],'Year':[],'Quater':[],'Regestered_users':[],'AppOpens':[]}\n",
    "State=[]\n",
    "Year=[]\n",
    "Quater=[]\n",
    "Brand=[]\n",
    "Count=[]\n",
    "Percentage=[]\n",
    "data2={'State':State,'Year':Year,'Quater':Quater,'Brand':Brand,'Count':Count,'Percentage':Percentage}\n",
    "path1=r\"C:\\Users\\kesav\\Guvi\\guvi main\\capstone_2\\pulse\\data\\aggregated\\user\\country\\india\\state\"\n",
    "t2_0=os.listdir(path1)#till state\n",
    "for i in t2_0:\n",
    "    p21=path1+'/'+i+'/'# select a state i\n",
    "    t21=os.listdir(p21)\n",
    "    for j in t21:\n",
    "        p22=p21+'/'+j+'/'\n",
    "        t22=os.listdir(p22)\n",
    "        year2 = datetime.strptime(j, '%Y').year\n",
    "        for k in t22:\n",
    "            p23=p22+'/'+k # select quater json file\n",
    "            d2=open(p23)\n",
    "            D2=json.load(d2)\n",
    "            for r in D2:\n",
    "                r_u=D2['data']['aggregated'][\"registeredUsers\"]\n",
    "                r_a=D2['data']['aggregated']['appOpens']\n",
    "                Data_r['Regestered_users'].append(r_u)\n",
    "                Data_r['AppOpens'].append(r_a)\n",
    "                Data_r['State'].append(i)\n",
    "                Data_r['Year'].append(int(year2))\n",
    "                Data_r['Quater'].append(int(k.strip('.json')))\n",
    "        for k in t22:\n",
    "            p23=p22+'/'+k # select quater json file\n",
    "            d3=open(p23)\n",
    "            D3=json.load(d3)\n",
    "            try:\n",
    "                for u in D3['data']['usersByDevice']:\n",
    "                            Brand.append(u['brand'])\n",
    "                            Count.append(u['count'])\n",
    "                            Percentage.append(u['percentage'])\n",
    "                            State.append(i)\n",
    "                            Year.append(j)\n",
    "                            Quater.append(int(k.strip('.json')))\n",
    "            except:\n",
    "                pass \n",
    "Df2=pd.DataFrame(Data_r)\n",
    "Df2.drop_duplicates(inplace=True, keep='last')\n",
    "Df2.reset_index(drop=True, inplace=True)\n",
    "Df2['State'] = Df2['State'].str.replace('-&-', ' & ')\n",
    "Df2['State'] = Df2['State'].str.replace('-', ' ')\n",
    "#Df_2['Year']=pd.to_datetime(Df_2['Year'],format='%Y')\n",
    "def cap(s):\n",
    "    return s.title()\n",
    "Df2['State']=Df2['State'].apply(cap)\n",
    "Df2['State'] = Df2['State'].str.replace('Islands','')\n",
    "for i,row in Df2.iterrows():\n",
    "    #here %S means string values \n",
    "    sql = \"INSERT INTO t_2 VALUES (%s,%s,%s,%s,%s)\"\n",
    "    mycursor.execute(sql, tuple(row))\n",
    "    # the connection is not auto committed by default, so we must commit to save our changes\n",
    "    mydb.commit()\n",
    "#table_name = 't_2'\n",
    "#Df2.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "for i in range (len(State)):\n",
    "    mycursor.execute('use capstone_2')\n",
    "    mycursor.execute('insert into t_3 (State,Year,Quater,Brand,Count,Percentage)values(%s,%s,%s,%s,%s,%s)',(State[i],Year[i],Quater[i],Brand[i],Count[i],Percentage[i]))\n",
    "    mydb.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map data transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating code for extracting the data and storing it in Panda's data frame and clearing the data in a required format and storing it into an sql database for the map visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datag1={'State':[],'Year':[],'Quater':[],'District':[],'Count':[],'Amount':[]}\n",
    "path4=r\"C:\\Users\\kesav\\Guvi\\guvi main\\capstone_2\\pulse\\data\\map\\transaction\\hover\\country\\india\\state\"\n",
    "tg=os.listdir(path4)\n",
    "for  i in tg:\n",
    "    pg1=path4+'/'+i+'/'\n",
    "    tg1=os.listdir(pg1)\n",
    "    for j in tg1:\n",
    "        pg2=pg1+'/'+j+'/'\n",
    "        tg2=os.listdir(pg2)\n",
    "        year_g1 = datetime.strptime(j, '%Y').year\n",
    "        for k in tg2:\n",
    "            pg3=pg2+k\n",
    "            dg=open(pg3)\n",
    "            Dg1=json.load(dg)\n",
    "            for t in Dg1['data']['hoverDataList']:\n",
    "                name_d=t['name']\n",
    "                cg=t['metric'][0]['count']\n",
    "                ag=t['metric'][0]['amount']\n",
    "                Datag1['State'].append(i)\n",
    "                Datag1['Year'].append(int(year_g1))\n",
    "                Datag1['Quater'].append(int(k.strip('.json')))\n",
    "                Datag1['District'].append(name_d)\n",
    "                Datag1['Count'].append(cg)\n",
    "                Datag1['Amount'].append(ag)\n",
    "           \n",
    "Df1_g=pd.DataFrame(Datag1)\n",
    "def cap(s):\n",
    "    return s.title()\n",
    "Df1_g['State']=Df1_g['State'].apply(cap)\n",
    "Df1_g['District'] = Df1_g['District'].str.replace('district', '')\n",
    "Df1_g['State'] = Df1_g['State'].str.replace('-&-', ' & ')\n",
    "Df1_g['State'] = Df1_g['State'].str.replace('Islands', '')\n",
    "Df1_g['State'] = Df1_g['State'].str.replace('-', ' ')\n",
    "\n",
    "# insert into tg_1 table\n",
    "for i,row in Df1_g.iterrows():\n",
    "#here %S means string values \n",
    "    sql = \"INSERT INTO tg_1 VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "    mycursor.execute(sql, tuple(row))\n",
    "    mydb.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the data and cleaning the data and storing the data in a sql table for map visualisation of users data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datagu1={'State':[],'Year':[],'Quater':[],'District':[],\"registeredUsers\":[],\"AppOpens\":[]}\n",
    "pathm_u=r'C:\\Users\\kesav\\Guvi\\guvi main\\capstone_2\\pulse\\data\\map\\user\\hover\\country\\india\\state'\n",
    "tmu=os.listdir(pathm_u)\n",
    "for i in tmu:\n",
    "    pmu1=pathm_u+'/'+i+'/'\n",
    "    tmu1=os.listdir(pmu1)\n",
    "    for j in tmu1:\n",
    "        pmu2=pmu1+'/'+j+'/'\n",
    "        tmu2=os.listdir(pmu2)\n",
    "        year_mu1 = datetime.strptime(j, '%Y').year\n",
    "        for k in tmu2:\n",
    "            pmu3=pmu2+k\n",
    "            dmu=open(pmu3)\n",
    "            Dmu1=json.load(dmu)\n",
    "            for district, data in Dmu1[\"data\"][\"hoverData\"].items():\n",
    "                Datagu1['State'].append(i)\n",
    "                Datagu1['Year'].append(int(year_mu1))\n",
    "                Datagu1['Quater'].append(int(k.strip('.json')))\n",
    "                Datagu1['District'].append(district)\n",
    "                Datagu1['registeredUsers'].append(data[\"registeredUsers\"])\n",
    "                Datagu1['AppOpens'].append(data[\"appOpens\"])\n",
    "\n",
    "Dfm_u=pd.DataFrame(Datagu1)\n",
    "def cap(s):\n",
    "    return s.title()\n",
    "Dfm_u['State']=Dfm_u['State'].apply(cap)\n",
    "Dfm_u['District'] = Dfm_u['District'].str.replace('district', '')\n",
    "Dfm_u['State'] = Dfm_u['State'].str.replace('-&-', ' & ')\n",
    "Dfm_u['State'] = Dfm_u['State'].str.replace('-', ' ')\n",
    "Dfm_u['State'] = Dfm_u['State'].str.replace('Islands', '')\n",
    "State=Dfm_u['State']\n",
    "Year=Datagu1['Year']\n",
    "Quater=Datagu1['Quater']\n",
    "District=Dfm_u['District']\n",
    "registered_users=Datagu1['registeredUsers']\n",
    "AppOpens=Datagu1['AppOpens']\n",
    "# insert into tg_2 table\n",
    "for i,row in Dfm_u.iterrows():\n",
    "    #here %S means string values \n",
    "    sql = \"INSERT INTO tg_2 VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "    mycursor.execute(sql, tuple(row))\n",
    "    mydb.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the data and cleaning the data and storing it in a sql table for top transactions of districts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "mydb = mysql.connector.connect(host=\"localhost\",user=\"root\",password=\"\")\n",
    "mycursor = mydb.cursor(buffered=True)\n",
    "mycursor.execute('use capstone_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8567"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data5={'State':[],'Year':[],'Quater':[],'Pincode':[],'Count':[],'Amount':[]}\n",
    "data5={'State':[],'Year':[],'Quater':[],'District':[],'count':[],'amount':[]}\n",
    "path5=r'C:\\Users\\kesav\\Guvi\\guvi main\\capstone_2\\pulse\\data\\top\\transaction\\country\\india\\state'\n",
    "t5=os.listdir(path5)\n",
    "for i in t5:\n",
    "    p1_5=path5+'/'+i+'/'\n",
    "    t1_5=os.listdir(p1_5)\n",
    "    for j in t1_5:\n",
    "        p2_5=p1_5+'/'+j+'/'\n",
    "        t2_5=os.listdir(p2_5)\n",
    "        year5 = datetime.strptime(j, '%Y').year\n",
    "        for k in t2_5:\n",
    "            p3_5=p2_5+k\n",
    "            d_5=open(p3_5)\n",
    "            D_5=json.load(d_5)\n",
    "            for t in D_5['data']['districts']:\n",
    "                \n",
    "                data5['State'].append(i)\n",
    "                data5['Year'].append(year5)\n",
    "                data5['Quater'].append(int(k.strip('.json')))\n",
    "                data5['District'].append(t['entityName'])\n",
    "                data5['count'].append(t['metric']['count'])\n",
    "                data5['amount'].append(t['metric']['amount'])\n",
    "            for t in D_5['data']['pincodes']:\n",
    "                Data5['State'].append(i)\n",
    "                Data5['Year'].append(year5)\n",
    "                Data5['Quater'].append(int(k.strip('.json')))\n",
    "                Data5['Pincode'].append(t['entityName'])\n",
    "                Data5['Count'].append(t['metric']['count'])\n",
    "                Data5['Amount'].append(t['metric']['amount'])\n",
    "            \n",
    "Df_5=pd.DataFrame(data5)\n",
    "Df_5['State'] = Df_5['State'].str.replace('-&-', ' & ')\n",
    "Df_5['State'] = Df_5['State'].str.replace('Islands', '')\n",
    "Df_5['State'] = Df_5['State'].str.replace('-', ' ')\n",
    "def cap(s):\n",
    "    return s.title()\n",
    "Df_5['State']=Df_5['State'].apply(cap)\n",
    "Df_5['State'] = Df_5['State'].str.replace('Islands', '')\n",
    "for i,row in Df_5.iterrows():\n",
    "    #here %S means string values \n",
    "    sql = \"INSERT INTO t_4 VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "    mycursor.execute(sql, tuple(row))\n",
    "    mydb.commit()\n",
    "Df_6=pd.DataFrame(Data5)\n",
    "Df_6=pd.DataFrame(Data5)\n",
    "Df_6['State'] = Df_6['State'].str.replace('-&-', ' & ')\n",
    "Df_6['State'] = Df_6['State'].str.replace('Islands', '')\n",
    "Df_6['State'] = Df_6['State'].str.replace('-', ' ')\n",
    "def cap(s):\n",
    "    return s.title()\n",
    "Df_6['State']=Df_6['State'].apply(cap)\n",
    "Df_6['State'] = Df_6['State'].str.replace('Islands', '')\n",
    "table_name = 't_5'\n",
    "Df_6.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting and transforming the data and storing it in the sql table of top registered users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7104"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6={'State':[],'Year':[],'Quater':[],'District':[],'registeredUsers':[]}\n",
    "path6=r'C:\\Users\\kesav\\Guvi\\guvi main\\capstone_2\\pulse\\data\\top\\user\\country\\india\\state'\n",
    "t6=os.listdir(path6)\n",
    "for i in t6:\n",
    "    p1_6=path6+'/'+i+'/'\n",
    "    t1_6=os.listdir(p1_6)\n",
    "    for j in t1_6:\n",
    "        p2_6=p1_6+'/'+j+'/'\n",
    "        t2_6=os.listdir(p2_6)\n",
    "        year6 = datetime.strptime(j, '%Y').year\n",
    "        for k in t2_6:\n",
    "            p3_6=p2_6+k\n",
    "            d_6=open(p3_6)\n",
    "            D_6=json.load(d_6)\n",
    "            for t in D_6['data']['districts']: \n",
    "                data6['State'].append(i)\n",
    "                data6['Year'].append(year6)\n",
    "                data6['Quater'].append(int(k.strip('.json')))\n",
    "                data6['District'].append(t[\"name\"])\n",
    "                data6['registeredUsers'].append(t[\"registeredUsers\"])\n",
    "Df_7=pd.DataFrame(data6)\n",
    "def cap(s):\n",
    "    return s.title()\n",
    "Df_7['State']=Df_7['State'].apply(cap)               \n",
    "Df_7['State'] = Df_7['State'].str.replace('-&-', ' & ')\n",
    "Df_7['State'] = Df_7['State'].str.replace('Islands', '')\n",
    "Df_7['State'] = Df_7['State'].str.replace('-', ' ')\n",
    "Df_7['State'] = Df_7['State'].str.replace('Islands', '')\n",
    "table_name = 't_6'\n",
    "Df_7.to_sql(table_name, con=engine, if_exists='append', index=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
